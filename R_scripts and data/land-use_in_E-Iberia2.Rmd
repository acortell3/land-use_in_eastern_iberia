---
title: "A Multi-method Approach with Machine Learning to Evaluating the Distribution and Intensity of Prehistoric Land Use in Eastern Iberia"
subtitle: "R Markdown Scripts for Reproducing Analyses"
author: "C Michael Barton"
date: "27 June 2023"
output: html_notebook
---


## Get all the packages ready

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggtext)
library(tidymodels)
library(caret)
library(ranger)
library(themis)
library(vip)
library(readr)
library(rcarbon)
library(Bchron)
library(doParallel)
library(parallel)

ncores <- max(1L, detectCores(), na.rm = TRUE)
options(Ncpus = ncores)
```


## Load data

```{r load Medland data}
# Load Medland survey collection data
medland_survey2014_2017 <- read_csv("data/medland_survey2014_2017.csv")

# Load training data for Random Forest modeling
training_data_E_Iberia <- read_csv("data/training_data_E_Iberia.csv")

# Load C14 data for SPD analysis
C14_SE_Iberia_all <- read_csv("data/C14_SE_Iberia_all.csv")

```


# Figures 1 and 2 generated in GIS software

# Figure 3: Surface Visibility and Artifact Recovery

```{r Figure 3, fig.height=8, fig.width=12}
medland_survey2014_2017 %>%
  dplyr::filter(area.sqm>0 & total.lithics>0 & !is.na(visibility)) %>%
  mutate(lithic.density=total.lithics/area.sqm) %>%
  ggplot(aes(x=lithic.density), xlim=.02) +
  geom_histogram(binwidth = .001) +
  scale_y_log10() +
  scale_x_continuous(limits = c(0,0.01), breaks = c(0,.002, .004, .006, .008)) +
  labs(title = "Surface Visibility and Artifact Recovery",
       x="lithic artifacts / km^2",
       y='count of patches') +
  facet_grid(factor(visibility)~study.area) +
  theme_bw(base_size = 20) +
  theme(axis.title.x = element_markdown())
```

### ANOVA for Figure 3: all survey areas and each survey area

```{r figure 3 ANOVA}
cat("\nCanal de Navarrés survey area\n")
with(medland_survey2014_2017 %>%
       dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Canal de Navarrés") %>%
       mutate(lithic.density=total.lithics/area.sqm),
  aov(lithic.density~visibility)) %>% summary()

cat("\nHoya de Buñol survey area\n")
with(medland_survey2014_2017 %>%
       dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Hoya de Buñol") %>%
       mutate(lithic.density=total.lithics/area.sqm),
  aov(lithic.density~visibility)) %>% summary()

cat("\nCocina/Catadau survey area\n")
with(medland_survey2014_2017 %>%
       dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Cocina/Catadau") %>%
       mutate(lithic.density=total.lithics/area.sqm),
  aov(lithic.density~visibility)) %>% summary()
```


# Random Forest Model for Chronological Unmixing (Figure 4 and Table 4)

## Data preparation

### Prepare data for Valencia dated assemblages

```{r prepare training data}


# Modify training data based on ML and Bayesian testing:
#  Merge ENEOL and MNEOL
#  Remove undiagnostic lithics for age estimates
#  Sort factor levels chronologically

training_data_E_Iberia <- training_data_E_Iberia %>%
  select(-undiag.lithics, -total.lithics, -citation) %>%
  mutate(period = replace(period, period == "MNEOL", "ENEOL"),
         period = factor(period,
                         levels = c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
```


### Prepare data from survey collections for applying Random Forest model
```{r prepare Medland data}
# filter out assemblages with only undiagnostic lithics
medland_survey2014_2017_lithics <- medland_survey2014_2017 %>%
  dplyr::filter(undiag.lithics < total.lithics) %>%
  select(ID, c(13:27))

# make separate table of assemblage ID and provenience
medland_survey2014_2017_info <- medland_survey2014_2017 %>%
  dplyr::filter(undiag.lithics < total.lithics) %>%
  mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = "")) %>%
  select(ID, study.area, assemblage)

# calculate lithic density for each collection patch
medland_survey2014_2017_density <- medland_survey2014_2017 %>%
  dplyr::filter(undiag.lithics < total.lithics) %>%
  mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = ""),
         density.km2 = total.lithics*1000/area.sqm)%>%
  select(ID, total.lithics, area.sqm,density.km2)
```

### Split data into training and test sets

```{r split training & test data}
# Partition into training and hold out test / validation sample
set.seed(456) ## if we want to make it completely reproducible
vl.split <- training_data_E_Iberia %>%
  rsample::initial_split(., prop=.75)

vl.train <- rsample::training(vl.split)
vl.test <- rsample::testing(vl.split)

# save ID data for later analysis
vl.test.id <- vl.test %>%
  select(ID, period)

```


### create v-fold objects for replicable and comparable cross-validation

10 folds using all the training data
```{r vfold10 all}
set.seed(456)
vf10.all <- vfold_cv(training_data_E_Iberia %>% select(-ID),v=10)
```

10 folds using the 75% training data split
```{r vfold10 train}
set.seed(456)
vf10.train <- vfold_cv(vl.train %>% select(-ID),v=10)
```


## Test Random Forest Model for Estimating Age of Surface Assemblages

### Create and evaluate RF model using a 75% split (vl.split)

#### Define and instantiate a random forest model

```{r RF define model}
valencia.lithics.rf.mod <-
  rand_forest(trees=500) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

print(valencia.lithics.rf.mod)
```

#### Fit the model to the training data

```{r RF fit model}
valencia.lithics.rf.fit <-
  valencia.lithics.rf.mod %>%
  fit(as.factor(period) ~ ., data = vl.train[,2:ncol(vl.train)])

print(valencia.lithics.rf.fit)
```

#### Optional graph: variable importance for random forest model with training set

```{r RF graph VIP, eval=FALSE}
valencia.lithics.rf.fit %>%
  extract_fit_engine() %>%
  vip(aesthetics = list(color = "black", fill = "#26ACB5"), num_features = 15) + theme_minimal()
```

#### Extract the fitted data

```{r RF extract model fit}
valencia.lithics.rf.predicted <-
  valencia.lithics.rf.fit %>%
  predict(vl.test) %>%
  bind_cols(vl.test.id[1:2], ., predict(valencia.lithics.rf.fit, vl.test, type="prob")) %>%
  rename(predicted.age = .pred_class,
         MP=.pred_MP,
         UP=.pred_UP,
         EPI=.pred_EPI,
         MESO=.pred_MESO,
         ENEOL=.pred_ENEOL,
         LNEOL=.pred_LNEOL,
         true.age = period) %>%
  mutate(true.age = factor(true.age,
           levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")),
         predicted.age = factor(predicted.age,
           levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))

print(valencia.lithics.rf.predicted)
```

#### Figure 4: Graph random forest predictions for test set

```{r Figure 4 RF graph predictions, fig.height=12, fig.width=16}
valencia.lithics.rf.predicted %>%
  pivot_longer(cols = 4:ncol(valencia.lithics.rf.predicted),
               names_to = "period", values_to = "probability") %>%
  mutate(period = factor(period,
      levels = c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL"))) %>%
  ggplot(aes(x=period, y=probability)) +
  geom_line(group=1) +
  geom_vline(aes(xintercept = true.age), color="red", size=2, alpha=.5) +
  geom_vline(aes(xintercept = predicted.age), color="blue", size=0.8) +
  labs(title="Random Forest Predictions for Each Assemblage",
       subtitle="black line indicates probability, blue line indicates predicted age, & red line indicates known age",
       x="time period",
       y="probability of predicted time period") +
  facet_wrap(vars(ID), ncol = 7) +
  theme_bw(base_size = 20) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
        strip.text.x = element_text(size = 14))
```

#### Create confusion matrix for 75% training/test split

```{r RF confusion matrix 1}
library(caret)
with(valencia.lithics.rf.predicted,  
  caret::confusionMatrix(true.age, predicted.age))
```

### Create and evaluate cross-validated random forest model using 10 folds

#### Define and instantiate a random forest model workflow and fit to cross-validated data set

```{r RF xvalidate fit model}
#Create workflow step
valencia.lithics.rf.wf <-
  workflow() %>%
  add_model(valencia.lithics.rf.mod) %>%
  add_formula(period ~ .) #The predictor is contained in add_formula method

set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
  valencia.lithics.rf.wf %>%
  fit_resamples(vf10.all,
                control=control_resamples(save_pred = TRUE))

print(valencia.lithics.rf.xv.fit)
```


#### Collect the cross-validated metrics

```{r RF xvalidate collect metrics}
# Collect the metrics using another model with cross-validation
valencia.lithics.rf.xv.meanpreds <- tune::collect_metrics(valencia.lithics.rf.xv.fit)
print(valencia.lithics.rf.xv.meanpreds)
```


#### Optional Graph: variable importance for cross-validated random forest model

```{r RF VIP all, eval=FALSE}
valencia.lithics.rf.mod %>%
  fit(as.factor(period) ~ ., data = training_data_E_Iberia[,2:ncol(training_data_E_Iberia)]) %>%
  extract_fit_engine() %>%
  vip(aesthetics = list(color = "black", fill = "#26ACB5"), num_features = 15) +
  theme_minimal()
```


#### Extract predictions of random forest model with cross-validation

```{r RF xvalidate predictions}
valencia.lithics.rf.xv.predictions <- collect_predictions(valencia.lithics.rf.xv.fit, summarize = TRUE) %>%
  arrange(.row) %>%
  rename(predicted.age = .pred_class,
         MP=.pred_MP,
         UP=.pred_UP,
         EPI=.pred_EPI,
         MESO=.pred_MESO,
         ENEOL=.pred_ENEOL,
         LNEOL=.pred_LNEOL,
         true.age=period) %>%
  select(-.row, -.config) %>%
  relocate(predicted.age, .after = true.age) %>%
  bind_cols(training_data_E_Iberia[1], .)

print(valencia.lithics.rf.xv.predictions)
```


#### Optional Graph: results for cross-validated random forest predictions

```{r RF xvalidate graph predictions, fig.height=10, fig.width=14, eval=FALSE}
valencia.lithics.rf.xv.predictions %>%
  pivot_longer(cols = 4:ncol(valencia.lithics.rf.xv.predictions), names_to = "period", values_to = "probability") %>%
  mutate(period = factor(period, levels = c("MP","UP","EPI","MESO","ENEOL","MNEOL","LNEOL"))) %>%
ggplot(aes(x=period, y=probability)) +
  geom_line(group=1) +
  geom_vline(aes(xintercept = true.age), color="red", size=2, alpha=.5) +
  geom_vline(aes(xintercept = predicted.age), color="blue", size=0.8) +
  labs(title="Random Forest with Cross-Validated Predictions",
       subtitle="Time Periods for Each Assemblage",
       x="predicted time period\n(blue line indicates prediction & red line indicates radiocarbon age)") +
  facet_wrap(vars(ID)) +
  theme_bw(base_size = 16) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```


#### Table 4: Confusion matrix for cross-validated random forest predictions

```{r Table 4 RF xvalidate confusion matrix}
caret::confusionMatrix(
  as.factor(valencia.lithics.rf.xv.predictions$true.age),
  as.factor(valencia.lithics.rf.xv.predictions$predicted.age))
```


## Create random forest model from all training data to estimate ages of surface collections from survey

### Define and instantiate a Random Forest model using all the known training data

```{r Medland RF define model}
medland.survey.rf.mod <-
  rand_forest(trees=500) %>%
  set_engine("ranger") %>%
  set_mode("classification")

print(medland.survey.rf.mod)
```

### Extract fit of Random Forest model

```{r Medland RF fit model}
medland.survey.rf.fit <-
  medland.survey.rf.mod %>%
  fit(as.factor(period) ~ ., data = training_data_E_Iberia[,2:ncol(training_data_E_Iberia)])

print(medland.survey.rf.fit)
```

### Apply Random Forest model to surface collections and generate age estimate predictions for each collection

```{r Medland RF extract model fit}
medland.survey.rf.predicted <-
  medland.survey.rf.fit %>%
  predict(medland_survey2014_2017_lithics) %>%
  bind_cols(medland_survey2014_2017_info, .,
            predict(medland.survey.rf.fit, medland_survey2014_2017_lithics, type="prob")) %>%
  rename(predicted.period = .pred_class,
         MP=.pred_MP,
         UP=.pred_UP,
         EPI=.pred_EPI,
         MESO=.pred_MESO,
         ENEOL=.pred_ENEOL,
         LNEOL=.pred_LNEOL) %>%
  mutate(predicted.period = factor(predicted.period,
           levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))

print(medland.survey.rf.predicted)
```

### Calculate age probabilities to assign to collections with only undiagostic lithics
Use the 10th percentile of probabilities from random forest model with dated collections

```{r age probabilities}
valencia.lithics.rf.probquantiles <- with(valencia.lithics.rf.xv.predictions %>%
       pivot_longer(cols = 4:ncol(valencia.lithics.rf.xv.predictions),
                    values_to = "probability"),
       quantile(probability, probs = c(.1, .25, .5, .75)))

print(paste("10th percentile of random forest probabilities =",
            valencia.lithics.rf.probquantiles[1]))

```

### Optional Graph: show quantiles for random forest probabilities

```{r graph age probabilities, eval=FALSE}
# show this in a graph
valencia.lithics.rf.xv.predictions %>%
  pivot_longer(cols = 4:ncol(valencia.lithics.rf.xv.predictions), names_to = "period", values_to = "probability") %>%
  mutate(period = factor(period, levels = c("MP","UP","EPI","MESO","ENEOL","MNEOL","LNEOL"))) %>%
  ggplot(aes(x=probability)) +
  geom_density() +
  geom_vline(xintercept = valencia.lithics.rf.probquantiles[1], color = 'red') +
  geom_vline(xintercept = valencia.lithics.rf.probquantiles[2], color = 'green') +
  geom_vline(xintercept = valencia.lithics.rf.probquantiles[3], color = 'blue') +
  geom_vline(xintercept = valencia.lithics.rf.probquantiles[4], color = 'green') +
  labs(title="Distribution of Combined Random Forest Predictions",
       x="age prediction probabilities \n(blue = median, red = 10th percentile, green = 25th and 75th percentile")

```

### Create files for additional graphing and for output for mapping

```{r Medland RF file for graphing}
# Create base file for graphing and output
medland.survey.rf.graph <-  
  left_join(select(medland_survey2014_2017, ID, study.area, zone, sector, subsector, total.lithics, area.sqm) %>%
            mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = "")),
            medland.survey.rf.predicted) %>%
  dplyr::filter(total.lithics>0) %>%
  mutate(density.km2 = total.lithics/area.sqm/1000)

# Create output file
# Use 10th percentile for overall ubiquity for patches with only undiagnostic lithics
medland.survey.rf.out <- medland.survey.rf.graph %>%
  mutate(MP = replace_na(MP, valencia.lithics.rf.probquantiles[1]),
         UP = replace_na(UP, valencia.lithics.rf.probquantiles[1]),
         EPI = replace_na(EPI, valencia.lithics.rf.probquantiles[1]),
         MESO = replace_na(MESO, valencia.lithics.rf.probquantiles[1]),
         ENEOL = replace_na(ENEOL, valencia.lithics.rf.probquantiles[1]),
         LNEOL = replace_na(LNEOL, valencia.lithics.rf.probquantiles[1])) %>%
  # occupational ubiquity
  rename(MP_ubiq = MP,
         UP_ubiq = UP,
         EPI_ubiq = EPI,
         MESO_ubiq = MESO,
         ENEOL_ubiq = ENEOL,
         LNEOL_ubiq = LNEOL) %>%
  # calculate occupational intensity
  mutate(MP_int = MP_ubiq*density.km2/800,
         UP_int = UP_ubiq*density.km2/250,
         EPI_int =  EPI_ubiq*density.km2/40,
         MESO_int = MESO_ubiq*density.km2/35,
         ENEOL_int = ENEOL_ubiq*density.km2/25,
         LNEOL_int = LNEOL_ubiq*density.km2/12)

# create file to graph results of patches with diagnostic lithics
medland.survey.rf.graph <-  medland.survey.rf.graph %>%
  dplyr::filter(!is.na(predicted.period)) %>%
  pivot_longer(cols = 10:15,
               names_to = "period",
               values_to = "ubiquity") %>%
   mutate(period = factor(period,
                         levels = c("MP","UP","EPI","MESO","ENEOL","MNEOL","LNEOL")),
         age = case_when(period == "MP" ~ 80000,
                         period == "UP" ~ 25000,
                         period == "EPI" ~ 13000,
                         period == "MESO" ~ 9000,
                         period == "ENEOL" ~ 6000,
                         period == "LNEOL" ~ 4000),
         predicted.age = case_when(
                         predicted.period == "MP" ~ 80000,
                         predicted.period == "UP" ~ 25000,
                         predicted.period == "EPI" ~ 13000,
                         predicted.period == "MESO" ~ 9000,
                         predicted.period == "ENEOL" ~ 6000,
                         predicted.period == "LNEOL" ~ 4000),
         duration.centuries = case_when(
                         period == "MP" ~ 800,
                         period == "UP" ~ 250,
                         period == "EPI" ~ 40,
                         period == "MESO" ~ 35,
                         period == "ENEOL" ~ 25,
                         period == "LNEOL" ~ 12))
```

### Optional Graph: occupational ubiquity for all survey patches with diagnostic lithics

```{r Medland RF graph ubiquity predictions, fig.height=12, fig.width=10, eval=FALSE, warning=FALSE}
medland.survey.rf.graph %>%
  ggplot(aes(x=period, y=ubiquity)) +
  geom_rect(aes(fill = study.area),xmin = -Inf,xmax = Inf, ymin = -Inf,ymax = Inf,alpha = 0.1) +
  geom_line(group=1) +
  #geom_vline(aes(xintercept = predicted.period), color="blue") +
  labs(title="Random Forest Age Estmates for Medland Survey Data",
       subtitle="Time Periods for Each Assemblage, Colored by Study Area",
       x="predicted time period\n(blue line indicates maximum predicted probability)") +
  facet_wrap(~ assemblage + ID) +
  theme_bw(base_size = 16) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

### Optional Graph: land use intensity for all survey patches with diagnostic lithics

```{r Medland RF graph intensity predictions, fig.height=12, fig.width=10, eval=FALSE, warning=FALSE}
medland.survey.rf.graph %>%
  ggplot(aes(x=period, y=ubiquity*density.km2/duration.centuries)) +
  geom_rect(aes(fill = study.area),xmin = -Inf,xmax = Inf, ymin = -Inf,ymax = Inf,alpha = 0.1) +
  geom_line(group=1) +
  #geom_vline(aes(xintercept = predicted.period), color="blue") +
  labs(title="Land Use Intensity Estmates for Medland Survey Data",
       subtitle="Time Periods for Each Assemblage, Colored by Study Area",
       x="predicted time period\n(blue line indicates maximum predicted probability)",
       y="estimated artifact accumulation rate\n(artifacts/km2/century)") +
  facet_wrap(~ assemblage + ID) +
  theme_bw(base_size = 16) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

### Figure 6a

```{r Figure 6a Medland RF graph ubiquity, fig.height=6, fig.width=12, warning=FALSE}
medland.survey.rf.graph %>%
  dplyr::filter(ID==238 | ID==960) %>%
ggplot(aes(x=period, y=ubiquity)) +
  geom_line(group=1, size=2) +
  labs(title="Occupational Ubiquity for 2 Survey Patches",
       subtitle="Random Forest Age Estmates",
       x="predicted time period",
       y="occupational ubiquity") +
  facet_wrap(~ assemblage) +
  theme_bw(base_size = 20) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

### Figure 6b

```{r Figure 6b Medland RF graph intensity, fig.height=6, fig.width=12, warning=FALSE}
medland.survey.rf.graph %>%
  dplyr::filter(ID==238 | ID==960) %>%
ggplot(aes(x=period, y=ubiquity*density.km2/duration.centuries)) +
  geom_line(group=1, size=2) +
  labs(title="Land Use Intensity for 2 Survey Patches",
       subtitle="Random Forest Age Estmates",
       x="predicted time period",
       y="artifacts / km^2 /century") +
  facet_wrap(~ assemblage) +
  theme_bw(base_size = 20) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
        axis.title.y = element_markdown())

```


#### Save random forest dating file to csv for mappoing in GIS

```{r Medland RF output, eval=FALSE}
write_csv(medland.survey.rf.out, "medland_survey_rf.csv")
```


## Aggregate summaries of ubiquity and intensity for each valley

### Calcuate area surveyed totals for each valley
```{r survey total by valley}
totals.surveyed <- medland_survey2014_2017 %>%
  select(study.area, area.sqm) %>%
  group_by(study.area) %>%
  summarise(total.area.sqm=sum(area.sqm))
```

### Figure 10a: aggregate ubiquity for each valley
```{r Figure 10a aggregate ubiquity, fig.height=8, fig.width=6}
left_join(medland.survey.rf.graph, totals.surveyed) %>%
  dplyr::filter(ubiquity > quantile(medland.survey.rf.graph$ubiquity,
                                     probs = .5)) %>%
  group_by(study.area, period) %>%
  summarize(area.sum = sum(area.sqm),
            total.area.sqm = first(total.area.sqm)) %>%
  select(study.area, period, area.sum, total.area.sqm) %>%
  mutate(pct.coverage = area.sum/total.area.sqm) %>%
  ungroup()  %>%
  add_row(study.area = "Canal de Navarrés",
          period = "EPI",
          area.sum = 0,
          total.area.sqm = 4107582,
          pct.coverage = 0) %>%
  add_row(study.area = "Cocina/Catadau",
          period = "EPI",
          area.sum = 0,
          total.area.sqm = 1095683,
          pct.coverage = 0) %>%
  add_row(study.area = "Cocina/Catadau",
          period = "MESO",
          area.sum = 0,
          total.area.sqm = 1095683,
          pct.coverage = 0) %>%
  add_row(study.area = "Hoya de Buñol",
          period = "EPI",
          area.sum = 0,
          total.area.sqm = 1551377,
          pct.coverage = 0) %>%

# Needed for optional upper quartile graphing   
  # add_row(study.area = "Canal de Navarrés",
  #         period = "MP",
  #         area.sum = 0,
  #         total.area.sqm = 4107582,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Canal de Navarrés",
  #         period = "MESO",
  #         area.sum = 0,
  #         total.area.sqm = 4107582,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Canal de Navarrés",
  #         period = "LNEOL",
  #         area.sum = 0,
  #         total.area.sqm = 4107582,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Cocina/Catadau",
  #         period = "MP",
  #         area.sum = 0,
  #         total.area.sqm = 1095683,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Cocina/Catadau",
  #         period = "LNEOL",
  #         area.sum = 0,
  #         total.area.sqm = 1095683,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Hoya de Buñol",
  #         period = "MP",
  #         area.sum = 0,
  #         total.area.sqm = 1551377,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Hoya de Buñol",
  #         period = "MESO",
  #         area.sum = 0,
  #         total.area.sqm = 1551377,
  #         pct.coverage = 0) %>%
  # add_row(study.area = "Hoya de Buñol",
  #         period = "LNEOL",
  #         area.sum = 0,
  #         total.area.sqm = 1551377,
  #         pct.coverage = 0) %>%


  ggplot(aes(x=factor(period, levels =
                  c('MP','UP','EPI','MESO','ENEOL','LNEOL')),
             y=pct.coverage, group=1)) +
  geom_line(lwd=1.5) +
  facet_wrap(~study.area, ncol = 1) +
  labs(title='Aggregate Occupational Ubiquity',
       subtitle='Proportion of study area surveyed\nwith ubiquity above the median',
       x='period',
       y='proportion') +
  theme_bw(base_size = 16)
```

### Figure 10b: aggregate intensity for each valley

```{r Figure 10b aggregate intensity, fig.height=8, fig.width=6}
left_join(medland.survey.rf.graph, totals.surveyed) %>%
  mutate(intensity = ubiquity*density.km2/duration.centuries) %>%
  dplyr::filter(intensity >= quantile(medland.survey.rf.graph$ubiquity*medland.survey.rf.graph$density.km2/medland.survey.rf.graph$duration.centuries, probs =.5)) %>%
  group_by(study.area, period) %>%
  summarize(area.sum = sum(area.sqm),
            total.area.sqm = first(total.area.sqm),
            density.km2 = first(density.km2)) %>%
  select(study.area, period, area.sum, total.area.sqm) %>%
  mutate(pct.coverage = area.sum/total.area.sqm) %>%
  ungroup %>%
  add_row(study.area = "Canal de Navarrés",
          period = "MP",
          area.sum = 0,
          total.area.sqm = 4107582,
          pct.coverage = 0) %>%
  add_row(study.area = "Hoya de Buñol",
          period = "MP",
          area.sum = 0,
          total.area.sqm = 1551377,
          pct.coverage = 0) %>%

# Needed for optional upper quartile graphing
  # add_row(study.area = "Hoya de Buñol",
  #         period = "UP",
  #         area.sum = 0,
  #         total.area.sqm = 1551377,
  #         pct.coverage = 0) %>%

  ggplot(aes(x=factor(period, levels =
                  c('MP','UP','EPI','MESO','ENEOL','LNEOL')),
             y=pct.coverage, group=1)) +
  geom_line(lwd=1.5) +
  facet_wrap(~study.area, ncol = 1) +
  labs(title='Aggregate Land Use Intensity',
       subtitle='Proportion of study area surveyed\nwith intensity above the median',
       x='period',
       y='proportion') +
  theme_bw(base_size = 16)
```


# Figure 11: SPD Analyses of Prehistoric Demography

## Prepare Data
Only use dates with COV ≤ 0.05
```{r prepare C14 data}
C14_SE_Iberia_all <- C14_SE_Iberia_all %>% dplyr::filter(C14.CV<0.05 & C14.SD>0)
```

## Calibrate Dates with BChron

```{r calibrate C14}
all.dates.calibrated <- with(C14_SE_Iberia_all, BchronCalibrate(ages = C14.mean, ageSds = C14.SD, calCurves = calib.curve, positions = site))

C14_SE_Iberia_all$BP.cal.median <- sapply(1:length(all.dates.calibrated), function(x) round(median(all.dates.calibrated[[x]]$ageGrid)))

```

## Bin Dates
```{r bin dates}
C14_SE_Iberia_all.bins <- C14_SE_Iberia_all %>%
  with(., binPrep(site, C14.mean, 100))
```

## Model Test
```{r SPD model test}
C14_SE_Iberia_all.modeltest <- C14_SE_Iberia_all %>%
  with(., calibrate(x=C14.mean, errors=C14.SD, calCurves = calib.curve, normalised=TRUE, calMatrix=FALSE)) %>%
  modelTest(.,
            errors = C14_SE_Iberia_all$C14.SD,
            timeRange = c(35000,3000),
            runm = 500,
            model="exponential",
            datenormalised=TRUE,
            nsim = 200,
            ncores = ncores,
            method = 'calsample',
            bins = C14_SE_Iberia_all.bins)
```

## Plot SPD
```{r Figure 11 plot SPD, fig.width=18, fig.height=8}
par(mar=c(7,7,7,3))
plot(C14_SE_Iberia_all.modeltest, xlim = c(30000,4000), col.obs = 'black', lwd.obs = 5, drawaxes = F)
axis(1, cex.axis = 2, pos = -.01, at=(seq(30000,0, by=-5000)))
axis(2, cex.axis = 2, pos = 30200)
mtext(side=1, line=5, "calibrated years BP", cex=2.5)
mtext(side=2, line=4, "summed probability density", cex=2.5)
title(main=paste("Southern and Eastern Iberia SPD (N = ", nrow(C14_SE_Iberia_all), ")\n"), cex.main = 3)
```
