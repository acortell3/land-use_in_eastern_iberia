facet_wrap(~study.area, ncol = 1) +
labs(title='Aggregate Land Use Intensity',
subtitle='Proportion of study area surveyed\nwith intensity above the median',
x='period',
y='proportion') +
theme_bw(base_size = 16)
par(mar=c(7,7,7,3))
plot(C14_SE_Iberia_all.modeltest, xlim = c(30000,4000), col.obs = 'black', lwd.obs = 5, drawaxes = F)
axis(1, cex.axis = 2, pos = -.01, at=(seq(30000,0, by=-5000)))
axis(2, cex.axis = 2, pos = 30200)
mtext(side=1, line=5, "calibrated years BP", cex=2.5)
mtext(side=2, line=4, "summed probability density", cex=2.5)
title(main=paste("Southern and Eastern Iberia SPD (N = ", nrow(C14_SE_Iberia_all), ")\n"), cex.main = 3)
par(mar=c(7,7,7,3))
plot(C14_SE_Iberia_all.modeltest, xlim = c(30000,4000), col.obs = 'black', lwd.obs = 5, drawaxes = F)
axis(1, cex.axis = 2, pos = -.01, at=(seq(30000,0, by=-5000)))
axis(2, cex.axis = 2, pos = 30200)
mtext(side=1, line=5, "calibrated years BP", cex=2.5)
mtext(side=2, line=4, "summed probability density", cex=2.5)
title(main=paste("Southern and Eastern Iberia SPD (N = ", nrow(C14_SE_Iberia_all), ")\n"), cex.main = 3)
par(mar=c(7,7,7,3))
plot(C14_SE_Iberia_all.modeltest, xlim = c(30000,4000), col.obs = 'black', lwd.obs = 5, drawaxes = F)
axis(1, cex.axis = 2, pos = -.01, at=(seq(30000,0, by=-5000)))
axis(2, cex.axis = 2, pos = 30200)
mtext(side=1, line=5, "calibrated years BP", cex=2.5)
mtext(side=2, line=4, "summed probability density", cex=2.5)
title(main=paste("Southern and Eastern Iberia SPD (N = ", nrow(C14_SE_Iberia_all), ")\n"), cex.main = 3)
source("~/Dropbox (ASU)/GitHub/land-use_in_eastern_iberia/R_scripts and data/land-use_in_E-Iberia.Rmd")
source("~/Dropbox (ASU)/GitHub/land-use_in_eastern_iberia/R_scripts and data/land-use_in_E-Iberia2.Rmd")
medland_survey2014_2017 %>%
dplyr::filter(area.sqm>0 & total.lithics>0 & !is.na(visibility)) %>%
mutate(lithic.density=total.lithics/area.sqm) %>%
ggplot(aes(x=lithic.density), xlim=.02) +
geom_histogram(binwidth = .001) +
scale_y_log10() +
scale_x_continuous(limits = c(0,0.01), breaks = c(0,.002, .004, .006, .008)) +
labs(title = "Surface Visibility and Artifact Recovery",
x="lithic artifacts / km^2",
y='count of patches') +
facet_grid(factor(visibility)~study.area) +
theme_bw(base_size = 20) +
theme(axis.title.x = element_markdown())
source("~/Dropbox (ASU)/GitHub/land-use_in_eastern_iberia/R_scripts and data/land-use_in_E-Iberia.Rmd")
cat("\nCanal de Navarrés survey area\n")
with(medland_survey2014_2017 %>%
dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Canal de Navarrés") %>%
mutate(lithic.density=total.lithics/area.sqm),
aov(lithic.density~visibility)) %>% summary()
cat("\nHoya de Buñol survey area\n")
with(medland_survey2014_2017 %>%
dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Hoya de Buñol") %>%
mutate(lithic.density=total.lithics/area.sqm),
aov(lithic.density~visibility)) %>% summary()
cat("\nCocina/Catadau survey area\n")
with(medland_survey2014_2017 %>%
dplyr::filter(total.lithics>0 & !is.na(visibility) & study.area == "Cocina/Catadau") %>%
mutate(lithic.density=total.lithics/area.sqm),
aov(lithic.density~visibility)) %>% summary()
# Modify training data based on ML and Bayesian testing:
#  Merge ENEOL and MNEOL
#  Remove undiagnostic lithics for age estimates
#  Sort factor levels chronologically
training_data_E_Iberia <- training_data_E_Iberia %>%
select(-undiag.lithics, -total.lithics, -citation) %>%
mutate(period = replace(period, period == "MNEOL", "ENEOL"),
period = factor(period,
levels = c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
# Load training data for Random Forest modeling
training_data_E_Iberia <- read_csv("data/training_data_E_Iberia.csv")
# Modify training data based on ML and Bayesian testing:
#  Merge ENEOL and MNEOL
#  Remove undiagnostic lithics for age estimates
#  Sort factor levels chronologically
training_data_E_Iberia <- training_data_E_Iberia %>%
select(-undiag.lithics, -total.lithics, -citation) %>%
mutate(period = replace(period, period == "MNEOL", "ENEOL"),
period = factor(period,
levels = c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
# filter out assemblages with only undiagnostic lithics
medland_survey2014_2017_lithics <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
select(ID, c(13:27))
# make separate table of assemblage ID and provenience
medland_survey2014_2017_info <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = "")) %>%
select(ID, study.area, assemblage)
# calculate lithic density for each collection patch
medland_survey2014_2017_density <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = ""),
density.km2 = total.lithics*1000/area.sqm)%>%
select(ID, total.lithics, area.sqm,density.km2)
#Create workflow step
valencia.lithics.rf.wf <-
workflow() %>%
add_model(valencia.lithics.rf.mod) %>%
add_formula(period ~ .) #The predictor is contained in add_formula method
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all,
control=control_resamples(save_pred = TRUE))
valencia.lithics.rf.wf <-
workflow() %>%
add_model(valencia.lithics.rf.mod) %>%
add_formula(period ~ .)
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all,
control=control_resamples(save_pred = TRUE))
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all, control=control_resamples(save_pred = TRUE))
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all, control=control_resamples(save_pred = TRUE))
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all, control=control_resamples(save_pred = TRUE))
set.seed(456)
vf10.all <- vfold_cv(training_data_E_Iberia %>% select(-ID),v=10)
set.seed(456)
vf10.train <- vfold_cv(vl.train %>% select(-ID),v=10)
# Partition into training and hold out test / validation sample
set.seed(456) ## if we want to make it completely reproducible
vl.split <- training_data_E_Iberia %>%
rsample::initial_split(., prop=.75)
vl.train <- rsample::training(vl.split)
vl.test <- rsample::testing(vl.split)
# save ID data for later analysis
vl.test.id <- vl.test %>%
select(ID, period)
set.seed(456)
vf10.all <- vfold_cv(training_data_E_Iberia %>% select(-ID),v=10)
set.seed(456)
vf10.train <- vfold_cv(vl.train %>% select(-ID),v=10)
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all, control=control_resamples(save_pred = TRUE))
valencia.lithics.rf.wf %>%
fit_resamples(vf10.all, control=control_resamples(save_pred = TRUE))
fit_resamples(resamples = vf10.all,
control=control_resamples(save_pred = TRUE))
valencia.lithics.rf.wf %>%
fit_resamples(resamples = vf10.all,
control=control_resamples(save_pred = TRUE))
# Load Medland survey collection data
medland_survey2014_2017 <- read_csv("data/medland_survey2014_2017.csv")
# Load training data for Random Forest modeling
training_data_E_Iberia <- read_csv("data/training_data_E_Iberia.csv")
# Load C14 data for SPD analysis
C14_SE_Iberia_all <- read_csv("data/C14_SE_Iberia_all.csv")
# Modify training data based on ML and Bayesian testing:
#  Merge ENEOL and MNEOL
#  Remove undiagnostic lithics for age estimates
#  Sort factor levels chronologically
training_data_E_Iberia <- training_data_E_Iberia %>%
select(-undiag.lithics, -total.lithics, -citation) %>%
mutate(period = replace(period, period == "MNEOL", "ENEOL"),
period = factor(period,
levels = c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
# filter out assemblages with only undiagnostic lithics
medland_survey2014_2017_lithics <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
select(ID, c(13:27))
# make separate table of assemblage ID and provenience
medland_survey2014_2017_info <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = "")) %>%
select(ID, study.area, assemblage)
# calculate lithic density for each collection patch
medland_survey2014_2017_density <- medland_survey2014_2017 %>%
dplyr::filter(undiag.lithics < total.lithics) %>%
mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = ""),
density.km2 = total.lithics*1000/area.sqm)%>%
select(ID, total.lithics, area.sqm,density.km2)
# Partition into training and hold out test / validation sample
set.seed(456) ## if we want to make it completely reproducible
vl.split <- training_data_E_Iberia %>%
rsample::initial_split(., prop=.75)
vl.train <- rsample::training(vl.split)
vl.test <- rsample::testing(vl.split)
# save ID data for later analysis
vl.test.id <- vl.test %>%
select(ID, period)
set.seed(456)
vf10.all <- vfold_cv(training_data_E_Iberia %>% select(-ID),v=10)
set.seed(456)
vf10.train <- vfold_cv(vl.train %>% select(-ID),v=10)
valencia.lithics.rf.mod <-
rand_forest(trees=500) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
print(valencia.lithics.rf.mod)
valencia.lithics.rf.fit <-
valencia.lithics.rf.mod %>%
fit(as.factor(period) ~ ., data = vl.train[,2:ncol(vl.train)])
print(valencia.lithics.rf.fit)
valencia.lithics.rf.predicted <-
valencia.lithics.rf.fit %>%
predict(vl.test) %>%
bind_cols(vl.test.id[1:2], ., predict(valencia.lithics.rf.fit, vl.test, type="prob")) %>%
rename(predicted.age = .pred_class,
MP=.pred_MP,
UP=.pred_UP,
EPI=.pred_EPI,
MESO=.pred_MESO,
ENEOL=.pred_ENEOL,
LNEOL=.pred_LNEOL,
true.age = period) %>%
mutate(true.age = factor(true.age,
levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")),
predicted.age = factor(predicted.age,
levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
print(valencia.lithics.rf.predicted)
#Create workflow step
valencia.lithics.rf.wf <-
workflow() %>%
add_model(valencia.lithics.rf.mod) %>%
add_formula(period ~ .) #The predictor is contained in add_formula method
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(resamples = vf10.all,
control=control_resamples(save_pred = TRUE))
View(C14_SE_Iberia_all.modeltest)
unregister_dopar <- function() {
env <- foreach:::.foreachGlobals
rm(list=ls(name=env), pos=env)
}
unregister_dopar()
#Create workflow step
valencia.lithics.rf.wf <-
workflow() %>%
add_model(valencia.lithics.rf.mod) %>%
add_formula(period ~ .) #The predictor is contained in add_formula method
set.seed(456) # For reproducibility
valencia.lithics.rf.xv.fit <-
valencia.lithics.rf.wf %>%
fit_resamples(resamples = vf10.all,
control=control_resamples(save_pred = TRUE))
print(valencia.lithics.rf.xv.fit)
# Collect the metrics using another model with cross-validation
valencia.lithics.rf.xv.meanpreds <- tune::collect_metrics(valencia.lithics.rf.xv.fit)
print(valencia.lithics.rf.xv.meanpreds)
valencia.lithics.rf.mod %>%
fit(as.factor(period) ~ ., data = training_data_E_Iberia[,2:ncol(training_data_E_Iberia)]) %>%
extract_fit_engine() %>%
vip(aesthetics = list(color = "black", fill = "#26ACB5"), num_features = 15) +
theme_minimal()
valencia.lithics.rf.xv.predictions <- collect_predictions(valencia.lithics.rf.xv.fit, summarize = TRUE) %>%
arrange(.row) %>%
rename(predicted.age = .pred_class,
MP=.pred_MP,
UP=.pred_UP,
EPI=.pred_EPI,
MESO=.pred_MESO,
ENEOL=.pred_ENEOL,
LNEOL=.pred_LNEOL,
true.age=period) %>%
select(-.row, -.config) %>%
relocate(predicted.age, .after = true.age) %>%
bind_cols(training_data_E_Iberia[1], .)
print(valencia.lithics.rf.xv.predictions)
caret::confusionMatrix(
as.factor(valencia.lithics.rf.xv.predictions$true.age),
as.factor(valencia.lithics.rf.xv.predictions$predicted.age))
medland.survey.rf.mod <-
rand_forest(trees=500) %>%
set_engine("ranger") %>%
set_mode("classification")
print(medland.survey.rf.mod)
medland.survey.rf.fit <-
medland.survey.rf.mod %>%
fit(as.factor(period) ~ ., data = training_data_E_Iberia[,2:ncol(training_data_E_Iberia)])
print(medland.survey.rf.fit)
medland.survey.rf.predicted <-
medland.survey.rf.fit %>%
predict(medland_survey2014_2017_lithics) %>%
bind_cols(medland_survey2014_2017_info, .,
predict(medland.survey.rf.fit, medland_survey2014_2017_lithics, type="prob")) %>%
rename(predicted.period = .pred_class,
MP=.pred_MP,
UP=.pred_UP,
EPI=.pred_EPI,
MESO=.pred_MESO,
ENEOL=.pred_ENEOL,
LNEOL=.pred_LNEOL) %>%
mutate(predicted.period = factor(predicted.period,
levels=c("MP", "UP", "EPI", "MESO", "ENEOL", "LNEOL")))
print(medland.survey.rf.predicted)
valencia.lithics.rf.probquantiles <- with(valencia.lithics.rf.xv.predictions %>%
pivot_longer(cols = 4:ncol(valencia.lithics.rf.xv.predictions),
values_to = "probability"),
quantile(probability, probs = c(.1, .25, .5, .75)))
print(paste("10th percentile of random forest probabilities =",
valencia.lithics.rf.probquantiles[1]))
# Create base file for graphing and output
medland.survey.rf.graph <-
left_join(select(medland_survey2014_2017, ID, study.area, zone, sector, subsector, total.lithics, area.sqm) %>%
mutate(assemblage = paste(study.area, "-", zone, "-", sector, "-", subsector, sep = "")),
medland.survey.rf.predicted) %>%
dplyr::filter(total.lithics>0) %>%
mutate(density.km2 = total.lithics/area.sqm/1000)
# Create output file
# Use 10th percentile for overall ubiquity for patches with only undiagnostic lithics
medland.survey.rf.out <- medland.survey.rf.graph %>%
mutate(MP = replace_na(MP, valencia.lithics.rf.probquantiles[1]),
UP = replace_na(UP, valencia.lithics.rf.probquantiles[1]),
EPI = replace_na(EPI, valencia.lithics.rf.probquantiles[1]),
MESO = replace_na(MESO, valencia.lithics.rf.probquantiles[1]),
ENEOL = replace_na(ENEOL, valencia.lithics.rf.probquantiles[1]),
LNEOL = replace_na(LNEOL, valencia.lithics.rf.probquantiles[1])) %>%
# occupational ubiquity
rename(MP_ubiq = MP,
UP_ubiq = UP,
EPI_ubiq = EPI,
MESO_ubiq = MESO,
ENEOL_ubiq = ENEOL,
LNEOL_ubiq = LNEOL) %>%
# calculate occupational intensity
mutate(MP_int = MP_ubiq*density.km2/800,
UP_int = UP_ubiq*density.km2/250,
EPI_int =  EPI_ubiq*density.km2/40,
MESO_int = MESO_ubiq*density.km2/35,
ENEOL_int = ENEOL_ubiq*density.km2/25,
LNEOL_int = LNEOL_ubiq*density.km2/12)
# create file to graph results of patches with diagnostic lithics
medland.survey.rf.graph <-  medland.survey.rf.graph %>%
dplyr::filter(!is.na(predicted.period)) %>%
pivot_longer(cols = 10:15,
names_to = "period",
values_to = "ubiquity") %>%
mutate(period = factor(period,
levels = c("MP","UP","EPI","MESO","ENEOL","MNEOL","LNEOL")),
age = case_when(period == "MP" ~ 80000,
period == "UP" ~ 25000,
period == "EPI" ~ 13000,
period == "MESO" ~ 9000,
period == "ENEOL" ~ 6000,
period == "LNEOL" ~ 4000),
predicted.age = case_when(
predicted.period == "MP" ~ 80000,
predicted.period == "UP" ~ 25000,
predicted.period == "EPI" ~ 13000,
predicted.period == "MESO" ~ 9000,
predicted.period == "ENEOL" ~ 6000,
predicted.period == "LNEOL" ~ 4000),
duration.centuries = case_when(
period == "MP" ~ 800,
period == "UP" ~ 250,
period == "EPI" ~ 40,
period == "MESO" ~ 35,
period == "ENEOL" ~ 25,
period == "LNEOL" ~ 12))
medland.survey.rf.graph %>%
dplyr::filter(ID==238 | ID==960) %>%
ggplot(aes(x=period, y=ubiquity)) +
geom_line(group=1, size=2) +
labs(title="Occupational Ubiquity for 2 Survey Patches",
subtitle="Random Forest Age Estmates",
x="predicted time period",
y="occupational ubiquity") +
facet_wrap(~ assemblage) +
theme_bw(base_size = 20) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
medland.survey.rf.graph %>%
dplyr::filter(ID==238 | ID==960) %>%
ggplot(aes(x=period, y=ubiquity*density.km2/duration.centuries)) +
geom_line(group=1, size=2) +
labs(title="Land Use Intensity for 2 Survey Patches",
subtitle="Random Forest Age Estmates",
x="predicted time period",
y="artifacts / km^2 /century") +
facet_wrap(~ assemblage) +
theme_bw(base_size = 20) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
axis.title.y = element_markdown())
totals.surveyed <- medland_survey2014_2017 %>%
select(study.area, area.sqm) %>%
group_by(study.area) %>%
summarise(total.area.sqm=sum(area.sqm))
left_join(medland.survey.rf.graph, totals.surveyed) %>%
dplyr::filter(ubiquity > quantile(medland.survey.rf.graph$ubiquity,
probs = .5)) %>%
group_by(study.area, period) %>%
summarize(area.sum = sum(area.sqm),
total.area.sqm = first(total.area.sqm)) %>%
select(study.area, period, area.sum, total.area.sqm) %>%
mutate(pct.coverage = area.sum/total.area.sqm) %>%
ungroup()  %>%
add_row(study.area = "Canal de Navarrés",
period = "EPI",
area.sum = 0,
total.area.sqm = 4107582,
pct.coverage = 0) %>%
add_row(study.area = "Cocina/Catadau",
period = "EPI",
area.sum = 0,
total.area.sqm = 1095683,
pct.coverage = 0) %>%
add_row(study.area = "Cocina/Catadau",
period = "MESO",
area.sum = 0,
total.area.sqm = 1095683,
pct.coverage = 0) %>%
add_row(study.area = "Hoya de Buñol",
period = "EPI",
area.sum = 0,
total.area.sqm = 1551377,
pct.coverage = 0) %>%
# Needed for optional upper quartile graphing
# add_row(study.area = "Canal de Navarrés",
#         period = "MP",
#         area.sum = 0,
#         total.area.sqm = 4107582,
#         pct.coverage = 0) %>%
# add_row(study.area = "Canal de Navarrés",
#         period = "MESO",
#         area.sum = 0,
#         total.area.sqm = 4107582,
#         pct.coverage = 0) %>%
# add_row(study.area = "Canal de Navarrés",
#         period = "LNEOL",
#         area.sum = 0,
#         total.area.sqm = 4107582,
#         pct.coverage = 0) %>%
# add_row(study.area = "Cocina/Catadau",
#         period = "MP",
#         area.sum = 0,
#         total.area.sqm = 1095683,
#         pct.coverage = 0) %>%
# add_row(study.area = "Cocina/Catadau",
#         period = "LNEOL",
#         area.sum = 0,
#         total.area.sqm = 1095683,
#         pct.coverage = 0) %>%
# add_row(study.area = "Hoya de Buñol",
#         period = "MP",
#         area.sum = 0,
#         total.area.sqm = 1551377,
#         pct.coverage = 0) %>%
# add_row(study.area = "Hoya de Buñol",
#         period = "MESO",
#         area.sum = 0,
#         total.area.sqm = 1551377,
#         pct.coverage = 0) %>%
# add_row(study.area = "Hoya de Buñol",
#         period = "LNEOL",
#         area.sum = 0,
#         total.area.sqm = 1551377,
#         pct.coverage = 0) %>%
ggplot(aes(x=factor(period, levels =
c('MP','UP','EPI','MESO','ENEOL','LNEOL')),
y=pct.coverage, group=1)) +
geom_line(lwd=1.5) +
facet_wrap(~study.area, ncol = 1) +
labs(title='Aggregate Occupational Ubiquity',
subtitle='Proportion of study area surveyed\nwith ubiquity above the median',
x='period',
y='proportion') +
theme_bw(base_size = 16)
left_join(medland.survey.rf.graph, totals.surveyed) %>%
mutate(intensity = ubiquity*density.km2/duration.centuries) %>%
dplyr::filter(intensity >= quantile(medland.survey.rf.graph$ubiquity*medland.survey.rf.graph$density.km2/medland.survey.rf.graph$duration.centuries, probs =.5)) %>%
group_by(study.area, period) %>%
summarize(area.sum = sum(area.sqm),
total.area.sqm = first(total.area.sqm),
density.km2 = first(density.km2)) %>%
select(study.area, period, area.sum, total.area.sqm) %>%
mutate(pct.coverage = area.sum/total.area.sqm) %>%
ungroup %>%
add_row(study.area = "Canal de Navarrés",
period = "MP",
area.sum = 0,
total.area.sqm = 4107582,
pct.coverage = 0) %>%
add_row(study.area = "Hoya de Buñol",
period = "MP",
area.sum = 0,
total.area.sqm = 1551377,
pct.coverage = 0) %>%
# Needed for optional upper quartile graphing
# add_row(study.area = "Hoya de Buñol",
#         period = "UP",
#         area.sum = 0,
#         total.area.sqm = 1551377,
#         pct.coverage = 0) %>%
ggplot(aes(x=factor(period, levels =
c('MP','UP','EPI','MESO','ENEOL','LNEOL')),
y=pct.coverage, group=1)) +
geom_line(lwd=1.5) +
facet_wrap(~study.area, ncol = 1) +
labs(title='Aggregate Land Use Intensity',
subtitle='Proportion of study area surveyed\nwith intensity above the median',
x='period',
y='proportion') +
theme_bw(base_size = 16)
par(mar=c(7,7,7,3))
plot(C14_SE_Iberia_all.modeltest, xlim = c(30000,4000), col.obs = 'black', lwd.obs = 5, drawaxes = F)
axis(1, cex.axis = 2, pos = -.01, at=(seq(30000,0, by=-5000)))
axis(2, cex.axis = 2, pos = 30200)
mtext(side=1, line=5, "calibrated years BP", cex=2.5)
mtext(side=2, line=4, "summed probability density", cex=2.5)
title(main=paste("Southern and Eastern Iberia SPD (N = ", nrow(C14_SE_Iberia_all), ")\n"), cex.main = 3)
